\section{Methodology}

\subsection{Validation and Numerical Workflow}

\subsubsection{Benchmark Case: AIJ Case H}
% Context: Describe the isolated building experiment at Tokyo Polytechnic University.
% Mention the Reynolds number and the inflow conditions (power law).
% Reference the Okaze et al. (2021) paper as the cross-validation target.

\begin{figure} [ht]
    \centering
    \includegraphics[width=0.8\linewidth]{figures/AIJ_setting.jpg}
    \caption{Experimental setup for AIJ Case H at Tokyo Polytechnic University,isolated building model and the arrangement of spires and roughness elements in the approach section to induce a turbulent boundary layer \parencite[adapted from][]{AIJCaseH, Okaze2021LES}.}
    \label{fig:AIJ_setting}
\end{figure}

The numerical validation of the Lattice Boltzmann Method (LBM) in this study is based on Case H of the Architectural Institute of Japan (AIJ) benchmark, which involves an isolated building model within a turbulent boundary layer. The physical experiment was conducted at Tokyo Polytechnic University using a 1:250 scale model. The building is a rectangular prism with a height-to-width ratio of $1:1:2$ ($H = 0.20$ m).The wind tunnel test section measures $2.8\,\text{m} \times 1.2\,\text{m} \times 1.0\,\text{m}$, corresponding to normalized dimensions of $14H \times 6H \times 5H$. Turbulence in the approach section was induced using spires and roughness elements to simulate a realistic atmospheric boundary layer. For the pollutant dispersion study, a tracer gas release point was located $50$ mm ($0.25H$) from the leeward side of the building. To ensure comparability across different scales, the reference velocity $U_H$ is defined as the mean inflow velocity at the building height.The LBM results in this research are cross-validated against the comprehensive Large Eddy Simulation (LES) study conducted by \textcite{Okaze2021LES}. Their study utilized OpenFOAM to investigate the influence of various subgrid-scale (SGS) models—including the Standard Smagorinsky (S), Dynamic Smagorinsky (DS), Wall-Adapting Local Eddy-Viscosity (WALE), and Coherent Structure (CS) models—on turbulent statistics. Notably, \textcite{Okaze2021LES} evaluated grid sensitivity across 10, 20, and 40-grid resolutions relative to the building width.This thesis focuses on comparing LBM performance against the validation study, using the same validation standards defined in the paper, which is a hit rate ($q$) of $\ge 0.66$ and a factor of two observations (FAC2) of $> 0.5$. By comparing the LBM-LSM results directly to these established OpenFOAM benchmarks, the predictive accuracy of the model can be evaluated.

\begin{figure} [ht]
    \centering
    \includegraphics[width=0.8\linewidth]{figures/Okaze_setting.jpg}
    \caption{Numerical domain configuration and measurement locations for the LES validation study  \parencite[adapted from][]{Okaze2021LES}.}
\label{fig:Okaze_setting}
\end{figure}

\subsubsection{Computational Implementation and Workflow}

The simulation framework is a high-performance heterogeneous system specifically optimized for GPU execution. It follows a modular design architecture where the Eulerian wind solver (LBM) and the Lagrangian particle tracker (LPT) are coupled in a one-way data flow. Based on the system's build configuration and modular \texttt{.mak} files, the architecture is categorized into six functional pillars:

\begin{enumerate} 
    \item \textbf{Fluid Core:} Manages the D3Q27 Lattice Boltzmann kernels, including the GPU-accelerated streaming and collision operators and Sub-Grid Scale (SGS) turbulence modeling. 
    \item \textbf{Particle Engine:} A dedicated subsystem for Lagrangian tracking that handles particle generation, GPU-based advection, and inter-node MPI communication for particle data.
    \item \textbf{Boundary and Solid Interface:} Resolves the interactions between the fluid phase and complex geometries (STL) or topography maps. 
    \item \textbf{State and Parameter Manager:} Handles the initialization of the MPI environment, domain decomposition, and fundamental fluid properties. 
    \item \textbf{Utility and Math Layer:} Provides the foundational logic for index mapping, memory allocation, and specialized LBM mathematical functions. 
    \item \textbf{I/O Subsystem:} Orchestrates data serialization into Paraview-compatible formats and custom user-defined results. 
\end{enumerate}

The operational workflow follows a parametric cycle that transitions from static configuration to high-performance execution. Initially, physical constants (such as surface roughness or latitude) and output sampling intervals are defined in the \texttt{Define\_user.h} header, while topographic assets are specified within \texttt{paramFluidProperty.cu}.

During the compilation phase, the \texttt{Makefile} utilizes the NVIDIA CUDA Compiler (\texttt{nvcc}) to compile the modular source list into a binary targeted for the specific GPU architecture (e.g., \texttt{sm\_90} for NVIDIA Hopper). This process "bakes" user-defined constants directly into the machine code, maximizing runtime performance. Finally, the execution is launched via the \texttt{runlbm.sh} script using \texttt{mpirun}, which passes dynamic arguments such as reference wind speed and memory allocation flags for the 30-million-particle Lagrangian array.

\begin{figure}[ht]
    \centering
    \begin{tikzpicture}[
        node distance=1.2cm and 0.8cm,
        box/.style={rectangle, draw, rounded corners, minimum width=2.8cm, minimum height=0.8cm, align=center, font=\small, fill=blue!5},
        header/.style={rectangle, draw, fill=orange!15, minimum width=2.5cm, font=\small\ttfamily, align=center},
        engine/.style={diamond, draw, fill=green!10, aspect=2, minimum width=3cm, font=\small\bfseries, align=center},
        util/.style={rectangle, draw, dashed, fill=gray!10, minimum width=2.5cm, font=\small, align=center},
        arrow/.style={-Stealth, thick}
    ]

        % 1. Input/Control Layer
        \node (config) [header] {Define\_user.h \\ paramFluidProperty.cu};
        \node (script) [header, right=of config] {runlbm.sh};
        \node (makefile) [box, below=0.8cm of $(config.south)!0.5!(script.south)$, fill=blue!10] {\textbf{Makefile / nvcc} \\ Build Orchestrator};

        % 2. Modular Source Layer (The .mak files)
        \node (lbm) [box, below=1.5cm of makefile] {LBM Solver \\ \textit{sourceList\_calculation}};
        \node (lpt) [box, right=of lbm] {Particle Tracker \\ \textit{SourceList\_Particle}};
        \node (param) [box, left=of lbm] {Param Manager \\ \textit{sourceList\_param}};
        \node (solid) [box, right=of lpt] {Solid/STL \\ \textit{sourceList\_solid}};
        
        % 3. Support Layer (The Function Library)
        \node (func) [util, below=0.6cm of $(lbm.south)!0.5!(lpt.south)$] {Utility Layer (Math/Alloc) \\ \textit{sourceList\_function}};

        % 4. Execution Core
        \node (gpu) [engine, below=1.2cm of func] {GPU Compute Kernel \\ (CUDA sm\_90)};

        % 5. Output Layer
        \node (output_mod) [box, left=of gpu, xshift=-0.5cm] {I/O Subsystem \\ \textit{sourceList\_output}};
        \node (data) [box, below=1cm of gpu, fill=red!5] {\textbf{Data Sink} \\ CSV (Wind) / Binary (Particle)};

        % Connections
        \draw [arrow] (config) -- (makefile);
        \draw [arrow] (script) -- (makefile);
        \draw [arrow] (makefile) -- (lbm);
        \draw [arrow] (makefile) -- (lpt);
        \draw [arrow] (makefile) -- (param);
        \draw [arrow] (makefile) -- (solid);
        
        % Functional layer interaction
        \draw [dashed] (func) -- (lbm);
        \draw [dashed] (func) -- (lpt);
        
        \draw [arrow] (lbm) -- (gpu);
        \draw [arrow] (lpt) -- (gpu);
        \draw [arrow] (param) -- (gpu);
        \draw [arrow] (solid) -- (gpu);
        
        \draw [arrow] (gpu) -- (output_mod);
        \draw [arrow] (output_mod) |- (data);
        \draw [arrow] (gpu) -- (data);
    \end{tikzpicture}
    \caption{System architecture of the LBM simulation framework}
    \label{fig:sys_arch}
\end{figure}

\begin{figure}[ht]
    \centering
    \begin{tikzpicture}[
        node distance=1cm and 0.8cm,
        box/.style={rectangle, draw, rounded corners, minimum width=2.8cm, minimum height=0.8cm, align=center, font=\small, fill=blue!5},
        header/.style={rectangle, draw, fill=orange!15, minimum width=2.5cm, font=\small\ttfamily, align=center},
        scheduler/.style={trapezium, trapezium left angle=70, trapezium right angle=110, draw, fill=purple!10, minimum width=3cm, font=\small\bfseries, align=center},
        engine/.style={diamond, draw, fill=green!10, aspect=1.8, minimum width=3.5cm, font=\small\bfseries, align=center},
        util/.style={rectangle, draw, dashed, fill=gray!10, minimum width=2.5cm, font=\small, align=center},
        arrow/.style={-Stealth, thick}
    ]

        % 1. Scheduler/Entry Layer
        \node (run_prog) [header] {run\_program.sh \\ \texttt{qsub -g jh250051}};
        \node (scheduler) [scheduler, below=0.8cm of run_prog] {TSUBAME 4.0 Scheduler \\ (Job Queue / Resource Allocation)};
        
        % 2. Batch Control Layer
        \node (mpirun_sh) [header, below=0.8cm of scheduler] {mpirun.sh \\ (Module Load / MPI Config)};
        \node (makefile) [box, left=1.5cm of mpirun_sh, fill=blue!10] {\textbf{Makefile} \\ \texttt{nvcc} (sm\_90)};

        % 3. Modular Source Layer
        \node (lbm) [box, below=1.5cm of mpirun_sh] {Fluid Solver \\ \textit{sourceList\_calculation}};
        \node (lpt) [box, right=of lbm] {Particle Tracker \\ \textit{SourceList\_Particle}};
        \node (param) [box, left=of lbm] {Param Manager \\ \textit{sourceList\_param}};
        \node (solid) [box, right=of lpt] {Solid/STL \\ \textit{sourceList\_solid}};
        
        % 4. Support Layer
        \node (func) [util, below=0.6cm of $(lbm.south)!0.5!(lpt.south)$] {Utility Layer \\ \textit{sourceList\_function}};

        % 5. High-Performance Execution
        \node (gpu) [engine, below=1.2cm of func] {Multi-Node Execution \\ (4 Nodes $\times$ 4 GPUs)};

        % 6. Output Layer
        \node (output_mod) [box, left=of gpu] {I/O Subsystem \\ \textit{sourceList\_output}};
        \node (data) [box, below=1cm of gpu, fill=red!5] {\textbf{Data Sink} \\ CSV (Wind) / Binary (Particle)};

        % Connections
        \draw [arrow] (run_prog) -- (scheduler);
        \draw [arrow] (scheduler) -- (mpirun_sh);
        \draw [arrow] (makefile) -- (mpirun_sh);
        
        \draw [arrow] (mpirun_sh) -- (lbm);
        \draw [arrow] (mpirun_sh) -- (lpt);
        \draw [arrow] (mpirun_sh) -- (param);
        \draw [arrow] (mpirun_sh) -- (solid);
        
        \draw [dashed] (func) -- (lbm);
        \draw [dashed] (func) -- (lpt);
        
        \draw [arrow] (lbm) -- (gpu);
        \draw [arrow] (lpt) -- (gpu);
        \draw [arrow] (param) -- (gpu);
        \draw [arrow] (solid) -- (gpu);
        
        \draw [arrow] (gpu) -- (output_mod);
        \draw [arrow] (output_mod) |- (data);
        \draw [arrow] (gpu) -- (data);

    \end{tikzpicture}
    \caption{System architecture of the LBM simulation framework executed using the TSUBAME 4.0 Supercomputer}
    \label{fig:tsubame_arch}
\end{figure}

\subsection{Simulation Parameters and Case Setup}
The specific configurations for the validation and research cases are summarized in Table~\ref{tab:simulation_cases_full}. These cases represent the transition from local prototyping to large-scale supercomputer execution.

\begin{table}[ht]
\centering
\caption{Detailed Simulation Case Parameters}
\label{tab:simulation_cases_full}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lcccccccc}
\hline
\textbf{Case} & \textbf{Environment} & \textbf{Domain Size ($x, y, z$ in m)} & \textbf{Duration (s)} & \textbf{Approach} & \textbf{$H_{cube}$ (m)} & \textbf{$z_0$ (m)} & \textbf{$U_0$ (m/s)} & \textbf{Flow Rate} \\ \hline
1 & Local Server & $832 \times 384 \times 240$ & 2400 & No & -- & 0.001 & 6.0 & 150 p/s \\
2 & TSUBAME 4.0 & $4352 \times 384 \times 320$ & 6000 & Yes & 8 & 0.001 & 6.0 & 150 p/s \\
3 & TSUBAME 4.0 & $4352 \times 384 \times 320$ & 6000 & Yes & 16 & 0.001 & 6.0 & 150 p/s \\
4 & TSUBAME 4.0 & $4352 \times 384 \times 320$ & 6000 & Yes & 20 & 0.001 & 6.0 & 150 p/s \\
5 & TSUBAME 4.0 & $4352 \times 384 \times 320$ & 6000 & Yes & 24 & 0.001 & 6.0 & 150 p/s \\
6 & TSUBAME 4.0 & $4352 \times 384 \times 320$ & 6000 & Yes & 32 & 0.001 & 6.0 & 150 p/s \\
7 & TSUBAME 4.0 & $4352 \times 384 \times 320$ & 6000 & Yes & 16 & 0.1 & 6.0 & 150 p/s \\
8 & TSUBAME 4.0 & $4352 \times 384 \times 320$ & 6000 & Yes & 20 & 0.1 & 6.0 & 150 p/s \\ \hline
\end{tabular}%
}
\end{table}

\subsection{Physical and Dimensionless Parameters}
To ensure the dynamic similarity between the wind tunnel experiment and the Lattice Boltzmann Method (LBM) simulation, the Reynolds number ($Re$) is calculated. This dimensionless value represents the ratio of inertial forces to viscous forces.\textbf{Reynolds Number ($Re$)}For this study, the characteristic length is defined as the building height $H$, and the velocity is the wind speed at that height $U_H$.

\begin{equation}
    Re = \frac{U_H \cdot H}{\nu}
\end{equation}

While the experimental $Re_{exp}$ is $4.3 \times 10^4$, the LBM simulation on TSUBAME 4.0 operates at a significantly higher effective Reynolds number ($Re_{LBM} \approx 2.09 \times 10^7$), reflecting the high-fidelity nature of the Large Eddy Simulation (LES) approach.

\subsubsection{Wind and Turbulence Data Post-Processing and Statistical Analysis}

The Large Eddy Simulation (LES) results were post-processed to extract time-averaged wind statistics and turbulence characteristics. The simulation domain was decomposed into four parallel sub-domains (indexed 0000 to 0003) for computational efficiency on the TSUBAME 4.0 supercomputer. 

Data analysis focused primarily on the fourth sub-domain (0003), which contains the building model and the validation points of interest, excluding the approach flow sections (0000–0002).

\textbf{Data Structure and Extraction}
Wind field data were exported as planar cross-sections ($xy$-planes) at various vertical grid heights ($k$). The raw output files follow a stacked structure where each height level is preceded by a header indicating the vertical grid index, followed by a $192 \times 544$ matrix representing the spanwise ($y$) and streamwise ($x$) velocity components. On the small domain simulation (Case 1), the data structure is similar, except for the inexistence of the approach section. Thus, for the small domain simulation, only one sub-domain, 0000, exists, and the analysis is done over that sub-domain only.

The analysis utilizes time-averaged velocity components ($\bar{u}, \bar{v}, \bar{w}$) and second-order velocity moments ($\overline{u^2}, \overline{v^2}, \overline{w^2}$), averaged over 540,000 time steps (equivalent to 5,400 physical seconds) to ensure statistical convergence. These variables correspond to the output files \texttt{xy\_um}, \texttt{xy\_vm}, \texttt{xy\_wm} (first-order moments) and \texttt{xy\_uu}, \texttt{xy\_vv}, \texttt{xy\_ww} (second-order moments).

\textbf{Turbulence Statistics}
To evaluate the turbulent flow characteristics, Reynolds stresses were calculated by subtracting the square of the mean velocity from the mean of the squared velocity. The streamwise ($\langle u'^2 \rangle$), spanwise ($\langle v'^2 \rangle$), and vertical ($\langle w'^2 \rangle$) Reynolds normal stresses were derived as follows:

\begin{align}
    \langle u'^2 \rangle &= \overline{u^2} - (\bar{u})^2 \\
    \langle v'^2 \rangle &= \overline{v^2} - (\bar{v})^2 \\
    \langle w'^2 \rangle &= \overline{w^2} - (\bar{w})^2 
\end{align}

\textbf{Root Mean Square (RMS) Fluctuations}
The Root Mean Square (RMS) velocity fluctuations, which indicate the intensity of turbulence in each direction, were calculated and normalized by the reference approach flow velocity ($U_H$) at building height $H$:

\begin{equation}
    u_{rms} = \frac{\sqrt{\langle u'^2 \rangle}}{U_H}, \quad v_{rms} = \frac{\sqrt{\langle v'^2 \rangle}}{U_H}, \quad w_{rms} = \frac{\sqrt{\langle w'^2 \rangle}}{U_H}
\end{equation}

\textbf{Turbulence Kinetic Energy (TKE)}
The Turbulence Kinetic Energy ($k$), representing the mean kinetic energy per unit mass associated with eddies in the turbulent flow, was computed as half the sum of the Reynolds normal stresses:

\begin{equation}
    k = \frac{1}{2} \left( \langle u'^2 \rangle + \langle v'^2 \rangle + \langle w'^2 \rangle \right)
\end{equation}

To handle numerical stability during post-processing, a constraint was applied such that any negative stress values resulting from floating-point errors were clamped to zero before the square root operation ($\text{max}(0, \sigma^2)$). All statistical results were mapped to the physical domain coordinates to facilitate direct comparison with the Architectural Institute of Japan (AIJ) wind tunnel experimental benchmarks.

\subsubsection{Lagrangian Particle Data Post-Processing and Statistical Analysis}

Due to the high temporal and spatial resolution of the Lagrangian tracking, the raw output is generated in a compact binary format to minimize I/O overhead. To translate these large-scale datasets into physically interpretable results, a dedicated post-processing suite was developed in C++. This suite follows a modular architecture, where specific physical quantities are computed by discrete analytical engines coordinated through a central execution framework. The post-processing workflow is orchestrated by a multi-threaded C++ executable, compiled via a modular \texttt{Makefile} that links specialized modules for density calculation, flux analysis, vertical profiling, and flux footprint prediction (FFP). The system is designed for high flexibility; rather than hard-coding simulation parameters, the tool utilizes a Command-Line Interface (CLI) where domain dimensions, grid size, time steps, and output intervals are passed as dynamic arguments at runtime. This allows the same analytical core to be applied across various experimental cases, ranging from local isolated building tests to large-scale urban simulations without the need for frequent re-compilation. Execution is managed through batch scripts (\texttt{run.bat}) For instance, the framework can simultaneously extract particle density profiles at specified heights ($z_{out}$) and compute the source area contributions at defined sensor locations. By leveraging OpenMP for multi-threading (\texttt{OMP\_NUM\_THREADS}), the post-processor efficiently iterates through millions of Lagrangian trajectories stored in the binary files, aggregating them into averaged statistical summaries (CSV or text format) suitable for final visualization in Python.

\subsection{Turbulence and Dispersion Modeling}

\textbf{Normalized Concentration ($C_{norm}$)} To allow for a direct comparison between experimental gas data and the Lagrangian particle model, concentration values are normalized based on the flow rate $Q$, velocity $U_H$, and building scale $H$.

\begin{equation}
    C_{norm} = \frac{C_o \cdot U_H \cdot H^2}{Q}
\end{equation}

\subsection{Statistical Validation Metrics}
Following the AIJ guidelines for urban wind environments, four metrics are used to compare the predicted values ($P_i$) against the observed experimental data ($O_i$).\textbf{Hit Rate ($q$)}The Hit Rate measures the reliability of the model. A data point is a "hit" if the prediction is within a relative tolerance $D$ (usually 0.25) or an absolute tolerance $W$ (usually 0.05).

\begin{equation}q = \frac{1}{N} \sum_{i=1}^{N} n_i, \quad n_i = 
    \begin{cases} 
        1 & \text{if } \left| \frac{P_i - O_i}{O_i} \right| \le D \text{ or } |P_i - O_i| \le W \\ 0 & \text{else} 
    \end{cases}
\end{equation}

\textbf{Factor of Two (FAC2)} FAC2 is a robust measure of the overall spread. It checks if the predicted value is between half and double the observed value.

\begin{equation}\text{FAC2} = \frac{1}{N} \sum_{i=1}^{N} n_i, \quad n_i = 
    \begin{cases} 
        1 & \text{if } 0.5 \le \frac{P_i}{O_i} \le 2.0 \\ 0 & \text{else} 
    \end{cases}
\end{equation}

\textbf{Error Metrics (MAE and RMSE)} The Mean Absolute Error (MAE) provides the average magnitude of the errors, while the Root Mean Square Error (RMSE) gives a higher weight to large outliers, providing a stricter assessment of simulation accuracy.

\begin{equation}
    \text{MAE} = \frac{1}{N} \sum_{i=1}^{N} |P_i - O_i|, \quad \text{RMSE} = \sqrt{\frac{1}{N} \sum_{i=1}^{N} (P_i - O_i)^2}\end{equation}

\newpage